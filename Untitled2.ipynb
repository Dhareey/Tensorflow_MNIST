{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4gMuclaXRIbKEfZ7FvK8c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhareey/Tensorflow_MNIST/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rstisJJ8nKo"
      },
      "source": [
        "# This Notebook is my Deep Learning Tuturial. Simply put, i will run a single layer perceptron on a dataset using both tensorflow and pytorch\n",
        "# Number of Epochs = 500.\n",
        "# Data to be used is the "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BroCKEtg-M69"
      },
      "source": [
        "# Import Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import torch\n",
        "from torch import nn\n",
        "train_data = pd.read_csv('/content/sample_data/mnist_train_small.csv')\n",
        "test_data = pd.read_csv('/content/sample_data/mnist_test.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "LOadNZ8qVzbP",
        "outputId": "4d164657-1cc3-4618-d70b-3020d8040b6b"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>0.10</th>\n",
              "      <th>0.11</th>\n",
              "      <th>0.12</th>\n",
              "      <th>0.13</th>\n",
              "      <th>0.14</th>\n",
              "      <th>0.15</th>\n",
              "      <th>0.16</th>\n",
              "      <th>0.17</th>\n",
              "      <th>0.18</th>\n",
              "      <th>0.19</th>\n",
              "      <th>0.20</th>\n",
              "      <th>0.21</th>\n",
              "      <th>0.22</th>\n",
              "      <th>0.23</th>\n",
              "      <th>0.24</th>\n",
              "      <th>0.25</th>\n",
              "      <th>0.26</th>\n",
              "      <th>0.27</th>\n",
              "      <th>0.28</th>\n",
              "      <th>0.29</th>\n",
              "      <th>0.30</th>\n",
              "      <th>0.31</th>\n",
              "      <th>0.32</th>\n",
              "      <th>0.33</th>\n",
              "      <th>0.34</th>\n",
              "      <th>0.35</th>\n",
              "      <th>0.36</th>\n",
              "      <th>0.37</th>\n",
              "      <th>0.38</th>\n",
              "      <th>...</th>\n",
              "      <th>0.551</th>\n",
              "      <th>0.552</th>\n",
              "      <th>0.553</th>\n",
              "      <th>0.554</th>\n",
              "      <th>0.555</th>\n",
              "      <th>0.556</th>\n",
              "      <th>0.557</th>\n",
              "      <th>0.558</th>\n",
              "      <th>0.559</th>\n",
              "      <th>0.560</th>\n",
              "      <th>0.561</th>\n",
              "      <th>0.562</th>\n",
              "      <th>0.563</th>\n",
              "      <th>0.564</th>\n",
              "      <th>0.565</th>\n",
              "      <th>0.566</th>\n",
              "      <th>0.567</th>\n",
              "      <th>0.568</th>\n",
              "      <th>0.569</th>\n",
              "      <th>0.570</th>\n",
              "      <th>0.571</th>\n",
              "      <th>0.572</th>\n",
              "      <th>0.573</th>\n",
              "      <th>0.574</th>\n",
              "      <th>0.575</th>\n",
              "      <th>0.576</th>\n",
              "      <th>0.577</th>\n",
              "      <th>0.578</th>\n",
              "      <th>0.579</th>\n",
              "      <th>0.580</th>\n",
              "      <th>0.581</th>\n",
              "      <th>0.582</th>\n",
              "      <th>0.583</th>\n",
              "      <th>0.584</th>\n",
              "      <th>0.585</th>\n",
              "      <th>0.586</th>\n",
              "      <th>0.587</th>\n",
              "      <th>0.588</th>\n",
              "      <th>0.589</th>\n",
              "      <th>0.590</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   6  0  0.1  0.2  0.3  0.4  ...  0.585  0.586  0.587  0.588  0.589  0.590\n",
              "0  5  0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "1  7  0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "2  9  0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "3  5  0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "4  2  0    0    0    0    0  ...      0      0      0      0      0      0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2PMJuaCWttW",
        "outputId": "8eee0c71-be78-428d-babb-524d44a67158"
      },
      "source": [
        "train_data.isnull().any() # No holes in data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6        False\n",
              "0        False\n",
              "0.1      False\n",
              "0.2      False\n",
              "0.3      False\n",
              "         ...  \n",
              "0.586    False\n",
              "0.587    False\n",
              "0.588    False\n",
              "0.589    False\n",
              "0.590    False\n",
              "Length: 785, dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-f0xFXeScui",
        "outputId": "36e93c6a-0bd4-42fb-c33a-97d1723c3d16"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19999, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIUPltnBQJA8"
      },
      "source": [
        "y_train = train_data.pop('6')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhGXmuQqSy3n",
        "outputId": "a5109e02-a76e-43c7-896c-f2feffe381f1"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        5\n",
              "1        7\n",
              "2        9\n",
              "3        5\n",
              "4        2\n",
              "        ..\n",
              "19994    0\n",
              "19995    1\n",
              "19996    2\n",
              "19997    9\n",
              "19998    5\n",
              "Name: 6, Length: 19999, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlW-BeFATNjx"
      },
      "source": [
        "# Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, x_test, y_train, y_test = train_test_split(train_data, y_train, test_size=0.3)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vGi3IklgpUz",
        "outputId": "f6f7b6c6-c33f-45ae-a5eb-42a620463060"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhzi1b_pg9F5"
      },
      "source": [
        "# Transform the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcfHs_2RKVXF"
      },
      "source": [
        "x_train_data = scaler.fit_transform(X_train)\n",
        "x_test_data = scaler.transform(x_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD7cIkeENkZE",
        "outputId": "06585b96-744c-450f-f564-7fca056a4a75"
      },
      "source": [
        "x_train_data.shape[1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBrqOkTxMErc"
      },
      "source": [
        "# Train the algorithm using temsorflow\n",
        "input_shape = [x_train_data.shape[1]]\n",
        "model = keras.Sequential([\n",
        "                          layers.Dense(units= 1024, activation='relu', input_shape= input_shape),\n",
        "                          layers.Dropout(0.3),\n",
        "                          layers.BatchNormalization(),\n",
        "                          layers.Dense(1024, activation='relu'),\n",
        "                          layers.Dropout(0.3),\n",
        "                          layers.BatchNormalization(),\n",
        "                          layers.Dense(784, activation='relu'),\n",
        "                          layers.Dropout(0.3),\n",
        "                          layers.BatchNormalization(),\n",
        "                          layers.Dense(500, activation='relu'),\n",
        "                          layers.Dropout(0.3),\n",
        "                          layers.BatchNormalization(),\n",
        "                          layers.Dense(150, activation='relu'),\n",
        "                          layers.Dropout(0.3),\n",
        "                          layers.BatchNormalization(),\n",
        "                          layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',loss='SparseCategoricalCrossentropy', metrics='accuracy')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO7ukaRhVyGN"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    patience= 20,\n",
        "    min_delta= 0.001,\n",
        "    restore_best_weights = True\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NMA3Av1d5YY"
      },
      "source": [
        "#from tensorflow.keras.utils import to_categorical\n",
        "#y_train = to_categorical(y_train, 10)\n",
        "#y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwbyUt_oUQhk",
        "outputId": "5a2c1022-c6dc-4bb3-fc23-3b933b8b50a7"
      },
      "source": [
        "history = model.fit(x_train_data,y_train, validation_data=(x_test_data,y_test),epochs=1000,callbacks=[early_stopping],batch_size= 256)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "55/55 [==============================] - 7s 120ms/step - loss: 0.8165 - accuracy: 0.7448 - val_loss: 0.3373 - val_accuracy: 0.9002\n",
            "Epoch 2/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.2825 - accuracy: 0.9166 - val_loss: 0.2269 - val_accuracy: 0.9375\n",
            "Epoch 3/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.2031 - accuracy: 0.9394 - val_loss: 0.1989 - val_accuracy: 0.9457\n",
            "Epoch 4/1000\n",
            "55/55 [==============================] - 6s 118ms/step - loss: 0.1543 - accuracy: 0.9535 - val_loss: 0.1921 - val_accuracy: 0.9535\n",
            "Epoch 5/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.1230 - accuracy: 0.9616 - val_loss: 0.1995 - val_accuracy: 0.9568\n",
            "Epoch 6/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.1083 - accuracy: 0.9668 - val_loss: 0.1743 - val_accuracy: 0.9592\n",
            "Epoch 7/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: 0.1902 - val_accuracy: 0.9612\n",
            "Epoch 8/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0744 - accuracy: 0.9758 - val_loss: 0.1803 - val_accuracy: 0.9615\n",
            "Epoch 9/1000\n",
            "55/55 [==============================] - 6s 118ms/step - loss: 0.0639 - accuracy: 0.9786 - val_loss: 0.1777 - val_accuracy: 0.9618\n",
            "Epoch 10/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0610 - accuracy: 0.9796 - val_loss: 0.1733 - val_accuracy: 0.9612\n",
            "Epoch 11/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0592 - accuracy: 0.9819 - val_loss: 0.1786 - val_accuracy: 0.9613\n",
            "Epoch 12/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.1752 - val_accuracy: 0.9623\n",
            "Epoch 13/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.1820 - val_accuracy: 0.9617\n",
            "Epoch 14/1000\n",
            "55/55 [==============================] - 6s 118ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.1816 - val_accuracy: 0.9623\n",
            "Epoch 15/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.1770 - val_accuracy: 0.9625\n",
            "Epoch 16/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0370 - accuracy: 0.9882 - val_loss: 0.1790 - val_accuracy: 0.9652\n",
            "Epoch 17/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.1729 - val_accuracy: 0.9650\n",
            "Epoch 18/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.1722 - val_accuracy: 0.9668\n",
            "Epoch 19/1000\n",
            "55/55 [==============================] - 7s 119ms/step - loss: 0.0307 - accuracy: 0.9896 - val_loss: 0.1819 - val_accuracy: 0.9637\n",
            "Epoch 20/1000\n",
            "55/55 [==============================] - 7s 118ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.1645 - val_accuracy: 0.9657\n",
            "Epoch 21/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.1734 - val_accuracy: 0.9647\n",
            "Epoch 22/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.1833 - val_accuracy: 0.9630\n",
            "Epoch 23/1000\n",
            "55/55 [==============================] - 6s 118ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.1866 - val_accuracy: 0.9647\n",
            "Epoch 24/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.1914 - val_accuracy: 0.9648\n",
            "Epoch 25/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.1834 - val_accuracy: 0.9643\n",
            "Epoch 26/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.1763 - val_accuracy: 0.9643\n",
            "Epoch 27/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.1777 - val_accuracy: 0.9640\n",
            "Epoch 28/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1650 - val_accuracy: 0.9663\n",
            "Epoch 29/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.1916 - val_accuracy: 0.9652\n",
            "Epoch 30/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0268 - accuracy: 0.9918 - val_loss: 0.1826 - val_accuracy: 0.9663\n",
            "Epoch 31/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.1844 - val_accuracy: 0.9678\n",
            "Epoch 32/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.1843 - val_accuracy: 0.9647\n",
            "Epoch 33/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.1838 - val_accuracy: 0.9668\n",
            "Epoch 34/1000\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.1632 - val_accuracy: 0.9690\n",
            "Epoch 35/1000\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.1743 - val_accuracy: 0.9688\n",
            "Epoch 36/1000\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.1685 - val_accuracy: 0.9662\n",
            "Epoch 37/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.1736 - val_accuracy: 0.9653\n",
            "Epoch 38/1000\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.1736 - val_accuracy: 0.9662\n",
            "Epoch 39/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1924 - val_accuracy: 0.9663\n",
            "Epoch 40/1000\n",
            "55/55 [==============================] - 6s 118ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1884 - val_accuracy: 0.9690\n",
            "Epoch 41/1000\n",
            "55/55 [==============================] - 7s 119ms/step - loss: 0.0105 - accuracy: 0.9961 - val_loss: 0.1930 - val_accuracy: 0.9677\n",
            "Epoch 42/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.1873 - val_accuracy: 0.9665\n",
            "Epoch 43/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.1862 - val_accuracy: 0.9660\n",
            "Epoch 44/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.1873 - val_accuracy: 0.9675\n",
            "Epoch 45/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.1870 - val_accuracy: 0.9662\n",
            "Epoch 46/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1822 - val_accuracy: 0.9677\n",
            "Epoch 47/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1813 - val_accuracy: 0.9668\n",
            "Epoch 48/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.1910 - val_accuracy: 0.9670\n",
            "Epoch 49/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1903 - val_accuracy: 0.9657\n",
            "Epoch 50/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0139 - accuracy: 0.9954 - val_loss: 0.1891 - val_accuracy: 0.9673\n",
            "Epoch 51/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.1905 - val_accuracy: 0.9662\n",
            "Epoch 52/1000\n",
            "55/55 [==============================] - 6s 115ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1933 - val_accuracy: 0.9663\n",
            "Epoch 53/1000\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.2022 - val_accuracy: 0.9668\n",
            "Epoch 54/1000\n",
            "55/55 [==============================] - 6s 117ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.1984 - val_accuracy: 0.9665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fAYK2sxyGS-"
      },
      "source": [
        "# Using Pytorch for the same algorithm but different hyperparameters\n",
        "# Hyperparameters:"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOsZyF25y8ml"
      },
      "source": [
        "# Define the model\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "#from torchsample.modules import ModuleTrainer\n",
        "\n",
        "# Build the Neural Net\n",
        "class neuNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(neuNet,self).__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "\"\"\"\n",
        "pymodel = nn.Sequential(\n",
        "    nn.Linear(784, 1024),\n",
        "    nn.ReLU(), \n",
        "    nn.Linear(1024, 784),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(784, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 10)\n",
        ")\n",
        "\"\"\"\n",
        "Net = neuNet()\n",
        "# Specify the loss function\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upt5DZ7eACrb",
        "outputId": "3893c0d6-74bd-46ee-ed5e-0eef423776a6"
      },
      "source": [
        "type(y_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZAfSDRdANPU"
      },
      "source": [
        "# Load x_train, x_test, y_train, y_test into dataloader for easy training\n",
        "import torch.utils.data as data_utils\n",
        "py_data_train = data_utils.TensorDataset(torch.Tensor(x_train_data),torch.Tensor(np.array(y_train)))\n",
        "py_data_valid = data_utils.TensorDataset(torch.Tensor(x_test_data), torch.Tensor(np.array(y_test)))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o7xK76zkSnr",
        "outputId": "e7d22990-36ee-4f87-d3da-404c9a97633e"
      },
      "source": [
        "train_loader = data_utils.DataLoader(py_data_train, batch_size=64, shuffle= True)\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nurLCnq28ILH",
        "outputId": "72bba567-111b-4ed7-adf9-92e9ee0a2330"
      },
      "source": [
        "# Train the model using 50 epochs\n",
        "epochs = 50\n",
        "train_loader = data_utils.DataLoader(py_data_train, batch_size=64, shuffle= True)\n",
        "for i in range(epochs):\n",
        "  running_loss = 0\n",
        "  for datum, label in train_loader:\n",
        "    datum = datum.view(datum.shape[0], -1)\n",
        "    optimizer.zero_grad()\n",
        "    # Run forward propagation\n",
        "    output = Net(datum)\n",
        "    # Calculate the loss\n",
        "    loss = loss_func(output, label.long())\n",
        "    # Back propagation\n",
        "    loss.backward()\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  else:\n",
        "    print(f\"Training loss: {running_loss/len(train_loader)}\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 2.3033565582205715\n",
            "Training loss: 2.303207119850263\n",
            "Training loss: 2.303394965385193\n",
            "Training loss: 2.303346497827469\n",
            "Training loss: 2.3034050791230922\n",
            "Training loss: 2.3033316135406494\n",
            "Training loss: 2.303361401710336\n",
            "Training loss: 2.3034585229882367\n",
            "Training loss: 2.303335343321709\n",
            "Training loss: 2.303381247063206\n",
            "Training loss: 2.3033407616288692\n",
            "Training loss: 2.303426476918399\n",
            "Training loss: 2.3032656957025397\n",
            "Training loss: 2.303336275222639\n",
            "Training loss: 2.3034109209226146\n",
            "Training loss: 2.3033754444557784\n",
            "Training loss: 2.3033659262199926\n",
            "Training loss: 2.303357956071967\n",
            "Training loss: 2.303387648438754\n",
            "Training loss: 2.303410609563192\n",
            "Training loss: 2.3032571278750624\n",
            "Training loss: 2.303330851472132\n",
            "Training loss: 2.3034135402609768\n",
            "Training loss: 2.3033160096434155\n",
            "Training loss: 2.303325840327293\n",
            "Training loss: 2.303359227637722\n",
            "Training loss: 2.3034232511912305\n",
            "Training loss: 2.3032987411708046\n",
            "Training loss: 2.303321781768102\n",
            "Training loss: 2.3033292685469537\n",
            "Training loss: 2.3033952146904655\n",
            "Training loss: 2.30335461712319\n",
            "Training loss: 2.303402438011344\n",
            "Training loss: 2.3033472337679233\n",
            "Training loss: 2.303346523955532\n",
            "Training loss: 2.303355981225837\n",
            "Training loss: 2.303310680607138\n",
            "Training loss: 2.3033353879571505\n",
            "Training loss: 2.3033427571597165\n",
            "Training loss: 2.303281901633903\n",
            "Training loss: 2.3034253610323554\n",
            "Training loss: 2.3033761564455077\n",
            "Training loss: 2.303321228724092\n",
            "Training loss: 2.303349596180328\n",
            "Training loss: 2.3033769925435386\n",
            "Training loss: 2.3034014288148925\n",
            "Training loss: 2.303350321234089\n",
            "Training loss: 2.303366478175333\n",
            "Training loss: 2.3033292565715913\n",
            "Training loss: 2.3033713946059415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "r5N7BhidTSiG",
        "outputId": "1c0f5079-0c1f-4d7a-9173-2b284d80e941"
      },
      "source": [
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.666939</td>\n",
              "      <td>0.790342</td>\n",
              "      <td>0.390116</td>\n",
              "      <td>0.882000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.230747</td>\n",
              "      <td>0.930852</td>\n",
              "      <td>0.230893</td>\n",
              "      <td>0.932500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.171133</td>\n",
              "      <td>0.947353</td>\n",
              "      <td>0.195543</td>\n",
              "      <td>0.945167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.136472</td>\n",
              "      <td>0.956068</td>\n",
              "      <td>0.206694</td>\n",
              "      <td>0.948833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.105431</td>\n",
              "      <td>0.965069</td>\n",
              "      <td>0.199542</td>\n",
              "      <td>0.952833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.666939  0.790342  0.390116      0.882000\n",
              "1  0.230747  0.930852  0.230893      0.932500\n",
              "2  0.171133  0.947353  0.195543      0.945167\n",
              "3  0.136472  0.956068  0.206694      0.948833\n",
              "4  0.105431  0.965069  0.199542      0.952833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xnYC6uFCsoJ2",
        "outputId": "c3aa7349-49eb-422f-b851-5830bd32d4c9"
      },
      "source": [
        "history_df[['loss', 'val_loss']].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f68e26ebd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_YU0qbXaSXn",
        "outputId": "03caf9f9-ae69-4fc3-f52c-cbb7fa2297b4"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17048    5\n",
              "10070    6\n",
              "13382    4\n",
              "8843     5\n",
              "13824    0\n",
              "        ..\n",
              "869      7\n",
              "12266    0\n",
              "4887     7\n",
              "1083     4\n",
              "11042    7\n",
              "Name: 6, Length: 13999, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAWMVwJtsjqS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWKP49IV4G9D"
      },
      "source": [
        "# Using Pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zehFDuWKTgc5"
      },
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from folium import Marker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyIvlbceTkYu"
      },
      "source": [
        "train_gdf = gpd.GeoDataFrame(train_data, geometry=gpd.points_from_xy(train_data.longitude, train_data.latitude))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "kiF2AUUmCZEj",
        "outputId": "654b7d4b-fb05-4646-ada1-f851514bb637"
      },
      "source": [
        "train_gdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "      <td>POINT (-114.31000 34.19000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "      <td>POINT (-114.47000 34.40000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "      <td>POINT (-114.56000 33.69000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "      <td>POINT (-114.57000 33.64000)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "      <td>POINT (-114.57000 33.57000)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_house_value                     geometry\n",
              "0    -114.31     34.19  ...             66900.0  POINT (-114.31000 34.19000)\n",
              "1    -114.47     34.40  ...             80100.0  POINT (-114.47000 34.40000)\n",
              "2    -114.56     33.69  ...             85700.0  POINT (-114.56000 33.69000)\n",
              "3    -114.57     33.64  ...             73400.0  POINT (-114.57000 33.64000)\n",
              "4    -114.57     33.57  ...             65500.0  POINT (-114.57000 33.57000)\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iQ70GdecCd_M",
        "outputId": "ba2e6660-eea2-4322-e2a6-8264771ad910"
      },
      "source": [
        "# Plot in a data\n",
        "m = folium.Map(location=[34.19, -114.31], tiles = 'openstreetmap', zoom_start =10)\n",
        "\n",
        "for id, rows in train_gdf.iterrows():\n",
        "  Marker([rows.latitude, rows.longitude]).add_to(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-647b1af34461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot in a data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m34.19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m114.31\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'openstreetmap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzoom_start\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarkerCLuster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlongitude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MarkerCLuster' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQThjkL5Dsqq",
        "outputId": "0b7dfb05-ceab-4881-e9c7-8ee5cc84982f"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=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 onload=\"this.contentDocument.open();this.contentDocument.write(atob(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f2e78664588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyxslQQsVylR"
      },
      "source": [
        "# So, create a simple linear model using pytorch and tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD71jDVUXnZj"
      },
      "source": [
        "input_shape = [11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riJGxh6AXEjp"
      },
      "source": [
        "# Tensorflow\n",
        "model = keras.Sequential([layers.Dense(units= 1, input_shape= input_shape)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5zjOJ3MaaqL",
        "outputId": "640a7548-27fd-47aa-93f3-5fe3f5390685"
      },
      "source": [
        "w,b = model.weights\n",
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'dense/kernel:0' shape=(11, 1) dtype=float32, numpy=\n",
            "array([[ 0.03263664],\n",
            "       [ 0.31583208],\n",
            "       [ 0.49245983],\n",
            "       [-0.5479635 ],\n",
            "       [-0.51875657],\n",
            "       [-0.00132865],\n",
            "       [ 0.3119052 ],\n",
            "       [ 0.411233  ],\n",
            "       [-0.46420488],\n",
            "       [-0.5085629 ],\n",
            "       [-0.48251295]], dtype=float32)>\n",
            "<tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tDMpBVWX-o5"
      },
      "source": [
        "# Pytorch\n",
        "from torch import nn\n",
        "torchmodel= nn.Sequential(nn.Linear(input_shape[0], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3ikniDeaY7lS",
        "outputId": "38d7a3a0-6628-46ec-e9f8-4f4ee7307ee0"
      },
      "source": [
        "torchmodel."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-c1fc93e0f0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'Sequential' object has no attribute 'weight'"
          ]
        }
      ]
    }
  ]
}